# 风控模型

## （一）信用违约风险基本概念

1. 信用违约风险

   交易对手未能履行约定契约中的义务而造成经济损失的风险

2. 组成部分

   + PD：违约概率
   + LGD：违约条件下的损失率
   + EAD：违约风险下的敞口暴露
   + RWA：风险权重资产
   + EL：期望损失

3. 信用违约主体

   个人、公司、主权

4. 个贷中的常用违约定义

   + M0：最后还款日的第二天到下一个账单日
   + M1：M0的延续，在未还款的第二个账单日到第二次账单的最后还款日
   + M2：M1的延续，在未还款的第三个账单日到第三个账单日的最后还款日

## （二）评分卡模型

1. 简介

   1. 定义

      + 以分数的形式来衡量风险几率的一种手段
      + 对未来一段时间内违约/逾期/失联概率的预测
      + 通常评分越高越安全
      + 根据使用场景分为申请评分卡 A卡、行为评分卡 B卡、催收评分卡 C卡、反欺诈评分卡 F卡（F卡不常用）

   2. 目的

      通过对借款人信用历史记录和业务活动记录的深度数据挖掘、分析和提炼，发现蕴藏在纷繁复杂数据中、反映消费者风险特征和预期信贷表现的知识和规律，并通过评分的方式总结出来，作为管理决策的科学依据。

   3. 意义

      相比于人工审批更加的客观、一致、准确，同时能够量化用户的风险程度，并且很大程度地提高审批效率（评分卡是在系统中自动实施的）。

   4. 类型

      1. 申请评分卡（A卡）
         + 属于贷前阶段
         + 目的在于预测申请时（申请信用卡、申请贷款）对申请人进行量化评估。
      2. 行为评分卡（B卡）
         + 属于贷后管理阶段
         + 目的在于预测使用时点（获得贷款、信用卡的使用期间）未来一定时间内逾期的概率。
      3. 催收评分卡（C卡）
         + 属于催收阶段
         + 用于催收管理，在借款人当前状态为逾期的情况下，预测未来该笔贷款变为坏账的概率。
      4. 反欺诈评分卡（F卡）
         + 属于贷前阶段
         + 用于对业务中的新用户可能存在的欺诈行为进行预测。

   5. 构建过程

      1. 数据分析：基于实际业务场景理解数据内容，发现数据与研究问题的关系。
      2. 数据处理：对原始数据进行处理，包括不同数据源间的数据合并、数据规整化处理、缺失值处理等环节。
      3. 特征选择：利用特征选择方法，筛选出预测能力强的有效特征，合理降低特征总维度。
      4. 特征分箱：对特征自变量进行离散化分箱处理。
      5. WOE转换：特征分箱处理后，将变量进行WOE编码转换。
      6. 模型建立：结合样本数据建立模型及模型参数输出过程。
      7. 模型评估：利用评估指标对模型效果进行评价。
      8. 评分转换：将模型概率转换为直观评分以及生成评分卡。
      9. 验证上线：验证评分卡效果，并上线持续监测。

   6. 优缺点

      优点

      + 易于使用。业务人员在操作时，只需要按照评分卡每样打分然后算个总分就能操作，不需要接受太多专业训练。
      + 直观透明。客户和审核人员都能知道看到结果，以及结果是如何产生的。
      + 应用范围广。芝麻信用分

      

      缺点

      + 在日益增长的数据前，有着大量数据资源却使用有限，造成数据资源的浪费。
      + 当信息维度高时，评分卡建模会变得非常困难。
      + 某些特征在不同时期的重要性不同，而评分卡并没有关注到这些。例如在疫情期间，和收入相关的特征重要度会上升。

   7. 选择逻辑回归而不是XGBOOST或神经网络的原因

      + 模型直观，可解释性强，易于理解，变量系数可以与业内知识做交叉验证，更容易让人信服。
      + 易于发现问题。当模型效果衰减的时候，logistic模型能更好的查找原因。

   

2. 常用特征

   + 个人信息：学历、性别、收入
   + 负债信息：在本金融机构或者其他金融机构负债情况
   + 消费能力：商品购买记录、出境游、奢侈品消费
   + 历史信用记录：历史逾期行为
   + 新兴数据：人际社交网络足迹、出行、个人财务

   

3. 非平衡样本

   1. 定义

      在分类问题中，每种类别的出现概率未必均衡

      + 信用风险：正常用户多于逾期/违约用户
      + 流失风险：留存用户多于流失用户

   2. 非平衡样本的隐患

      降低对少类样本的灵敏性

   3. 解决方法

      1. 过采样：尽量多地增加少数类的的样本数量
         + 优点：简单，对数据质量要求不高
         + 缺点：过拟合
      2. 欠采样：减少多数类的数量
         + 优点：简单，对数据质量要求不高
         + 缺点：丢失重要信息

      3. SMOTE（合成少数过采样技术）
         + 优点：不易过拟合，保留信息
         + 缺点：不能对有缺失值和类别变量做处理

   4. SMOTE算法

      1. 定义

         基于随机过采样算法的一种改进方案，基本思想是对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中。

      2. 算法流程
         + 计算出每个少数类样本的K个近邻;
         + 从K个近邻中随机挑选N个样本进行随机线性插值，构造新的少数类样本;（随机线性插值：在特征空间中，每个少数类样本与它们的每个近邻样本连成一条直线，随机在直线上选取一点（每条直线只取一次），则为新构成的样本）
         + 将新样本与原数据合成，产生新的训练集
      3. 算法思想
         + 随机选取n个少数的样本，找出初始扩展的少类样本
         + 再找出最靠近它的m个少类样本，在任选最临近的m个少数类样本中的任意一点，从这两点上任选一点，这点就是新增的数据样本。
      4. 缺陷
         + 在近邻选择时,存在一定的盲目性
         + 无法克服非平衡数据集的数据分布，容易产生分布边缘化的问题。也就是说正负样本的边界可能会越来越模糊，虽然使数据集平衡性得到改善，但加大了分类算法进行分类的难度。

4. 数据预处理

   原始数据带有一定的格式，需要转化成正确的格式

   1. 利率

      百分比转化成浮点数

   2.  日期

      转化成Python时间

   3. 工作年限

      ''<1year''转化成0，">10years"转化成11

   4. 文本数据
      1. 主题提取
         + 优点：准确、详细
         + 缺点：模型复杂，需要足够多的训练样本
      2. 编码
         + 优点：简单
         + 缺点：信息丢失很高
   5. 缺失值
      1. 缺失值种类
         + 完全随机缺失
         + 随机缺失
         + 完全非随机缺失
      2. 处理方法
         + 补缺
         + 作为一种状态

5. 构建特征（特征衍生）

   + 计数：过去一年内申请贷款的总次数
   + 求和：过去一年内的网店消费总额
   + 比例：贷款申请额度与年收入的占比
   + 时间差：第一次开户距今时长
   + 波动率：过去3年内每份工作的时间的标准差

   

6. 分箱

   1. 定义

      对特征变量进行区间划分或者对不同枚举值进行合并的过程，它可以降低特征的复杂度，提升变量可解释性。

   2. 功能

      1. 拆分
         + 对 “连续变量” 进行分段离散化，使它变成 “离散变量”。比如：年龄、月收入。
         + 分为等频拆分、等距拆分、信息熵分箱。
      2. 合并
         + 减少离散变量的状态数，对 “离散变量” 进行合并。比如：城市、学历。

   3. 重要性

      + 稳定性：避免特征中无意义的波动对评分带来的波动
      + 健壮性：避免了极端值影响

   4. 注意事项

      + 每个变量的分箱数，控制在十个以下，通常 5个左右是最佳的；
      + 每个箱子里的样本数至少为总样本数的5%以上，每个箱子里都要有正负样本，同时坏样本率与箱子呈单调关系。
      + 分箱越多，模型过拟合的风险越高，模型的稳定性也会变差，在金融场景，风险可控与稳定至关重要。

   5. 优缺点

      优点

      + 会 “降低特征变量的复杂度，降低模型过拟合的风险”（因为特征中值的数量变少了，每个取值的样本量增多，也就是说方差会相比于分箱前变小，而偏差会变大）；
      + 可以 “增强模型的稳定性”，对特征变量的异常波动不会反应太大，也利于适应更广泛的客群；
      + 将特征变量划分为有限的分箱，可以 “增强模型的可解释性”；
      + 可以更自然地将 “缺失值作为单独的分箱”。

      

      缺点

      + 分箱后丢失了数据的细节信息，使模型对好坏样本的判别能力变弱了，模型的KS和AUC相比于分箱前会下降。

   6. Best-KS

      1. 原理

         让分箱后组别的分布的差异最大化

      2. 对于连续变量
         + 第一步，排序
         + 第二步，计算每一点的KS值
         + 第三步，选取最大的KS对应的特征值，将数据分为两部分
         + 第四步，对于每一部分，重复2-3，直到满足终止条件之一
      3. 对于离散度很高的变量
         + 编码
         + 依据连续变量的方式进行分箱
      4. 终止条件
         + 下一步分箱后，最小的箱的占比低于设定的阈值（0.05）
         + 下一步分箱后，该箱对应的y类别全部为0或1
         + 下一步分箱后，bad rate单调

   7. 卡方分箱

      1. 定义

         自底而上的数据离散化方法，依赖于卡方检验，具有最小卡方值的相邻区间合并在一起，直到满足确定的停止准则

      2. 原理

         + 它以卡方分布和卡方值为基础，判断某个因素是否会影响目标变量。例如，在检验性别是否会影响违约概率时，可以用卡方检验来判断。

         + 卡方检验的无效假设H0是：观察频数与期望频数没有差别，即该因素不会影响到目标变量。
         + 基于该假设计算出χ2值，它表示观察值与理论值之间的偏离程度。根据χ2分布及自由度可以确定在H0假设成立的情况下获得当前统计量及更极端情况的概率P。
         + 如果P值很小，说明观察值与理论值偏离程度太大，应当拒绝无效假设，表示比较资料之间有显著差异；否则就不能拒绝无效假设，尚不能认为样本所代表的实际情况和理论假设有差别。

      3. 步骤

         + 将数值变量A排序后分成区间较多的若干组，设为A_1,A_2,…,A_n（如果变量取值超过一百种可以采用等距的方法划分100箱）
         + 计算A_1 与A_2合并后的卡方值，A_2 与A_3合并后的卡方值，直至A_(n-1) 与A_n合并后的卡方值
         + 找出上一步所有合并后的卡方值中最小的一个，假设为A_(i-1) 与A_i,将其合并形成新的A_(i-1)
         + 不断重复2和3，直至满足终止条件

      4. 终止条件

         + 某次合并后，最小的卡方值的p值超过0.9（或0.95，0.99等）[卡方值越大，P值越小，相关性越强，对Y的解释性越好]
         + 某侧合并后，总的未合并的区间数达到指定的数目（例如5，10，15等）

7. WOE编码

   一种有监督的编码方式，将预测类别的集中度的属性作为编码的数值

   1. 定义

      WOE （证据权重）

      组内坏样本数量与总坏样本数量的比值与组内好样本数数量与总好样本数量的比值的差异，这个差异是两个比值的比值。
      $$
      WOE = ln{\frac{( 坏样本 / 总坏样本 )}{( 好样本 / 总好样本 )}}\\=ln{\frac{( 坏样本 / 好样本 )}{( 总坏样本 / 总好样本 )}}
      $$
      IV 

      IV值是woe值的加权求和。主要是消除各分组中数量差异带来的误差（消除分组样本分布不均匀带来的影响）。
      $$
      IV_i = [\frac{坏样本}{总坏样本}-\frac{好样本}{总好样本}]*WOE\\
      IV = \sum_{i=1}^{n}{IV_i}
      $$

   2. 取值

      + 组内响应比例越高（负样本占组内样本比例）WOE越大，所以要消除分组数量差异带来的影响。
      + 当组内无负样本的时候，woe=负无穷、iv对应正无穷。
      + 当组内无正样本数是woe对应正无穷、iv对应负无穷，不管iv等于正无穷还是负无穷都是无意义的。
      + 这也是IV的一个缺点，不能自动处理变量的分组中出现响应比例为0或者100%的情况
      + IV值小于0.02代表无预测能力，一般0.02-0.1低，0.1-0.3中，0.3-0.5高，大于等于0.5代表可疑， 一般我们选取0.2到0.5的特征，也就是预测能力中到预测能力高的特征。

   3. 为什么进行WOE编码

      因为WOE表示的是当前分箱中好坏客户的比例与总体好坏客户比例的差异，WOE的绝对值越大，这种差异就越明显，契合风控场景。

   4. 优缺点

      优点

      + 通过WOE编码可以对自变量X进行转换，使编码后的变量与因变量Y呈单调关系（是因为WOE编码后再通过逻辑回归拟合可以很好地契合评分卡公式）。
      + 对于稀疏变量，可以通过分箱将稀疏的值聚集到较大的组别，并最终可以使用 WOE 来表示整个组别的信息。提高模型的解释性。
      + 编码后特征的取值变少，在训练模型时能更快的收敛，提高了训练速度。
      + woe化之后可以计算每个特征的IV值，用来筛选特征。

      缺点

      + 由于最终分箱数量较少，会导致一定的信息丢失。
      + 未考虑自变量之间的相关性，即没有特征交互。
      + 计算过程利用了Y标签信息，因此存在特征穿越风险。

      特征穿越

      也可以叫做数据泄露，由于样本划分的策略，导致测试集中的信息引入到了训练集中，导致评估结果会更偏爱过拟合的模型，从而导致评估结果不够准确。

8. 变量选择

   1. 重要性

      + 共线性会造成信息冗余、符号失真
      + 加剧后期验证、部署、监控的负担
      + 业务含以上不充分

   2. 依据

      1. 约束：LASSO
      2. 特征重要性：随机森林
      3. 模型拟合优度和复杂度：基于AIC的逐步回归
      4. 变量信息度：IV

   3. 单变量分析

      1. 目的

         根据变量的某些属性，从初选名单中选取合适的变量进入缩减名单

      2. 涉及的变量属性
         + 变量显著性（高IV）
         + 变量的分布
         + 变量的业务含义
      3. 思想
         + 以分箱后的WOE为值
         + 有IV检验有效性
         + 连续变量bad rate的单调性（可以放宽到U型）
         + 单一区间的占比不宜过高

   4. 多变量分析

      1. 变量的两两相关性

         当相关性高时，只保留一个：

         + 选择IV高的
         + 选择分箱均衡的

      2. 变量的多重共线性

         用VIF来衡量：
         $$
         VIF_i = \frac{1}{1-R_i^2}
         $$
         Ri方为其他变量对变量i线性回归的R方

         + 要求VIF<10
         + 当某个变量VIF超过10，需要逐一剔除解释变量
         + 当剔除变量K时发现VIF<10，从变量1到K中剔除IV较低的一个

9. 相关指标

   1. KS值

      1. 定义

         + KS指标倾向于从概率角度衡量正负样本分布之间的差异。
         + 正是因为正负样本之间的模糊性和连续性，所以KS也是一条连续曲线。但最终为什么取一个最大值，主要原因是提取KS曲线中的一个显著特征，从而便于相互比较。
         + 召回率与假阳率的差值的最大值为特征的KS值，也就是累计正样本率大于累计负样本率的最大值，因为我们想抓到更多的坏人，也就是提高召回率，减少抓错的好人，减低假阳率。

      2. 取值范围

         + KS值范围为（0-1），一般选取0.2-0.75的特征，>0.75说明特征可能不可靠或者有误。

      3. 优点

         KS值不仅能够评价模型的区分能力，也能够评价单个特征的区分能力，前提是特征是有序且是线性的。

      4. 计算步骤

         + 计算每个评分区间的好坏账户数。
         + 计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。
         + 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的KS值。

      5. KS曲线

         KS曲线横坐标是评分区间或者是数据集百分比，纵坐标是假阳率和召回率，特征的ks=max|TPR-FPR|，对应下图红色曲线的最高点。其中召回率曲线（绿色曲线）在假阳率曲线（紫色曲线）上方。

   2. PSI值

      1. 定义

         PSI （Population Stability Index）称为群体稳定性指标，用来 “对比2个数据集的分布，是否发生比较大的偏差”，对比一定要有参照物，对评分卡模型来说，参照物是模型训练时的 “训练样本” (期望分布)，而评估对象称为 “验证样本”(实际分布)。
         $$
         psi = \sum_{i=1}^{n}{(A_i-E_i)*ln{(A_i/E_i)}}
         $$
         其中，A_i为实际分布，E_i为期望分布

      2. 取值

         PSI 可从两个计算维度来看，即评分 PSI和特征变量 PSI。PSI越小代表模型越稳定

         + 一般认为PSI小于0.1时候模型稳定性很高

         + 0.1-0.25代表模型良好，需要检测变化的原因
         + 大于0.25代表模型稳定性差，需要进一步分析特征变量，或者迭代模型。

      3. 应用场景

         + 可以对 “入模的每个特征变量” 进行分箱，在验证集与训练集上做PSI对比，判断样本是否发生大的变化。
         + PSI也可以做跨期验证。确保 “评分值、每个特征变量”，在近N个月的验证集上，对比训练集计算出的PSI，在可接受的范围内。

   3. WOE与IV值

      1. 定义

         WOE 

         组内坏样本数量与总坏样本数量的比值与组内好样本数数量与总好样本数量的比值的差异，这个差异是两个比值的比值。
         $$
         WOE = ln{\frac{( 坏样本 / 总坏样本 )}{( 好样本 / 总好样本 )}}\\=ln{\frac{( 坏样本 / 好样本 )}{( 总坏样本 / 总好样本 )}}
         $$
         IV 

         IV值是woe值的加权求和。主要是消除各分组中数量差异带来的误差（消除分组样本分布不均匀带来的影响）。
         $$
         IV_i = [\frac{坏样本}{总坏样本}-\frac{好样本}{总好样本}]*WOE\\
         IV = \sum_{i=1}^{n}{IV_i}
         $$

      2. 取值

         + 组内响应比例越高（负样本占组内样本比例）WOE越大，所以要消除分组数量差异带来的影响。
         + 当组内无负样本的时候，woe=负无穷、iv对应正无穷。
         + 当组内无正样本数是woe对应正无穷、iv对应负无穷，不管iv等于正无穷还是负无穷都是无意义的。
         + 这也是IV的一个缺点，不能自动处理变量的分组中出现响应比例为0或者100%的情况
         + IV值小于0.02代表无预测能力 一般0.02-0.1低，0.1-0.3中，0.3-0.5高，大于等于0.5代表可疑 一般我们选取0.2到0.5的特征，也就是预测能力中到预测能力高的特征。

      3. 为什么进行WOE编码

         因为WOE表示的是当前分箱中好坏客户的比例与总体好坏客户比例的差异，WOE的绝对值越大，这种差异就越明显，契合风控场景。

      4. 优缺点

         优点

         + 通过WOE编码可以对自变量X进行转换，使编码后的变量与因变量Y呈单调关系（是因为WOE编码后再通过逻辑回归拟合可以很好地契合评分卡公式）。
         + 对于稀疏变量，可以通过分箱将稀疏的值聚集到较大的组别，并最终可以使用 WOE 来表示整个组别的信息。提高模型的解释性。
         + 编码后特征的取值变少，在训练模型时能更快的收敛，提高了训练速度。
         + woe化之后可以计算每个特征的IV值，用来筛选特征。

         缺点

         + 由于最终分箱数量较少，会导致一定的信息丢失。
         + 未考虑自变量之间的相关性，即没有特征交互。
         + 计算过程利用了Y标签信息，因此存在特征穿越风险。

         特征穿越

         也可以叫做数据泄露，由于样本划分的策略，导致测试集中的信息引入到了训练集中，导致评估结果会更偏爱过拟合的模型，从而导致评估结果不够准确。





